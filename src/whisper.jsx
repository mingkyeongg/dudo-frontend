import React, { useState, useRef } from "react";

const AudioRecorder = () => {
  const [recording, setRecording] = useState(false);
  const [audioUrl, setAudioUrl] = useState(null);
  const [transcript, setTranscript] = useState(null);
  const mediaRecorder = useRef(null);
  const audioChunks = useRef([]);

  // ğŸ¤ ë…¹ìŒ ì‹œì‘
  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      mediaRecorder.current = new MediaRecorder(stream);
      audioChunks.current = [];

      mediaRecorder.current.ondataavailable = (event) => {
        audioChunks.current.push(event.data);
      };

      mediaRecorder.current.onstop = async () => {
        const audioBlob = new Blob(audioChunks.current, { type: "audio/webm" });
        const audioFile = new File([audioBlob], "recorded_audio.webm", {
          type: "audio/webm",
        });

        setAudioUrl(URL.createObjectURL(audioBlob));
        await transcribeAudio(audioFile);
      };

      mediaRecorder.current.start();
      setRecording(true);
    } catch (error) {
      console.error("ğŸ¤ ë§ˆì´í¬ ì ‘ê·¼ ì‹¤íŒ¨:", error);
    }
  };

  // â¹ï¸ ë…¹ìŒ ì¤‘ì§€
  const stopRecording = () => {
    if (mediaRecorder.current && recording) {
      mediaRecorder.current.stop();
      setRecording(false);
    }
  };

  // ğŸ“ Whisper APIë¡œ ì „ì†¡ í›„ í…ìŠ¤íŠ¸ ë³€í™˜
  const transcribeAudio = async (audioFile) => {
    const formData = new FormData();
    formData.append("file", audioFile);
    formData.append("model", "whisper-1");

    try {
      const response = await fetch("https://api.openai.com/v1/audio/transcriptions", {
        method: "POST",
        headers: {
          Authorization: `Bearer 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`,
        },
        body: formData,
      });

      const data = await response.json();
      setTranscript(data.text);
    } catch (error) {
      console.error("ğŸ“ Whisper API ìš”ì²­ ì‹¤íŒ¨:", error);
    }
  };

  return (
    <div>
      <button onClick={recording ? stopRecording : startRecording}>
        {recording ? "â¹ï¸ ë…¹ìŒ ì¤‘ì§€" : "ğŸ¤ ë…¹ìŒ ì‹œì‘"}
      </button>
      {audioUrl && <audio controls src={audioUrl}></audio>}
      {transcript && <p>ğŸ“ ë³€í™˜ëœ í…ìŠ¤íŠ¸: {transcript}</p>}
    </div>
  );
};

export default AudioRecorder;
